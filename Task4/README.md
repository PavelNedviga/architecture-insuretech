# Задание 4. Проектирование продажи ОСАГО

Компания планирует вскоре запустить новый продукт: **оформление ОСАГО онлайн**.

Пользовательский путь выглядит так:

- клиенту предлагается заполнить заявку с информацией о своём автомобиле,
- после этого сервис запрашивает у всех доступных страховых компаний предложения с условиями страхования под заявку клиента.

Бизнесу важно, чтобы на экране пользователя предложения от каждой страховой компании отображались сразу, как только от неё пришёл ответ. Максимальное время ожидания решения от страховой компании — 60 секунд.

Все страховые компании предоставляют однотипные REST API с двумя эндпоинтами:

- создать заявку на ОСАГО,
- получить предложение по заявке.

Бизнес предполагает, что в пик нагрузки количество одновременных пользователей, создающих заявку на ОСАГО, может достигать 2,5 тысячи человек.

Вы обсудили задачу с командой разработки и приняли такие решения:

1. Сохранить подход, который использовался для получения данных о продуктах и тарифах из страховых компаний.
2. Выделить отдельный сервис для взаимодействия со страховыми компаниями — `osago-aggregator`.

Функциональная обязанность этого сервиса — отправка заявок в страховые компании и дальнейший опрос решений по ним для передачи результатов в core-app. Остальная функциональность, связанная с оформлением ОСАГО, остаётся на стороне бэкенда в core-app.

Теперь вам нужно проработать ещё несколько моментов, исходя из требований бизнеса. Доработайте схему, которая у вас получилась в третьем задании. Отразите на ней ваши решения по этим вопросам:

Проработайте реализацию osago-aggregator. Решите:

1. Требуется ли ему своё хранилище данных?
2. Какой API он предоставляет core-app?
3. Определите средство интеграции между сервисами core-app и osago-aggregator.
4. Подумайте над API для веб-приложения в core-app.
5. Определите средство интеграции между веб-приложением и core-app. Если будете использовать средство, отличное от REST, отразите интеграцию новой стрелкой.
6. В зависимости от выбранных средств интеграции подумайте, требуется ли где-то применение паттернов отказоустойчивости:

- Rate Limiting,
- Circuit Breaker,
- Retry,
- Timeout.
Отобразите применение паттернов [на схеме](https://code.s3.yandex.net/software-architect/%D0%9E%D0%B1%D0%BE%D0%B7%D0%BD%D0%B0%D1%87%D0%B5%D0%BD%D0%B8%D1%8F%20%D0%BF%D0%B0%D1%82%D1%82%D0%B5%D1%80%D0%BD%D0%BE%D0%BC%20%D0%BE%D1%82%D0%BA%D0%B0%D0%B7%D0%BE%D1%83%D1%81%D1%82%D0%BE%D0%B8%CC%86%D1%87%D0%B8%D0%B2%D0%BE%D1%81%D1%82%D0%B8.drawio) с помощью обозначений из этой библиотеки.

7. Примите во внимание, что сервисы задеплоены в нескольких экземплярах. Подумайте, зависит ли ваше решение от этого.

Загрузите новый вариант схемы в директорию Task4 в рамках пул-реквеста.

## Osago-aggregator arc design notes

### Новый сервис osago-aggregator

| Решение | Почему |
|---------|--------|
| **Собственное хранилище** (PostgreSQL) | Нужно хранить: `client_quote_id ↔ insurer_app_id`, статусы, цену, raw-ответ. Долгоживущие опросы (но отвечающие требованию <= 60 с) переживают рестарт Pod’а. |
| **Внутренний API (gRPC + Protobuf)** | • Streaming-RPC «QuotesStream» даёт core-app отдельный поток предложений.<br>• gRPC легко мапится на HTTP/2, бинарно эффективен, поддерживает deadline/metadata. |
| **Выход наружу** — REST к страховым | Каждая страховая уже даёт REST; используем готовый HTTP-клиент с Resilience4j (см. паттерны). |

### API core-app - gRPC методы

```protobuf
service OsagoAggregator {
    rpc QuotesStream (QuoteStreamRequest) returns (stream QuoteOffer) {}
}
```

### Интеграция `core-app` и `osago-aggregator`

* gRPC-стрим выставляется через **Ingress Nginx** с sticky-session (`affinity: cookie`). Выступает в роли балансировщика и обратного прокси. Принимает HTTP/HTTPS-трафик снаружи кластера и маршрутизирует его на нужный Service/Pod.
  * sticky-session - политика балансировщика, заставляющая все запросы одного сетевого клиента отправлять на одну и ту же бэкенд-реплику.
  * `affinity: cookie` Конкретная реализация sticky-session в Ingress-NGINX: контроллер генерирует cookie (INGRESSCOOKIE, route и т. п.) и при последующих запросах направляет клиента на ту же Pod.
* Все Pods `osago-aggregator` читают из одной очереди внутренних job-pollers; за счёт sticky hash-partition минимизируем дубли.
  * sticky hash-partition - алгоритм распределения задач по потребителям: ключ (например insurerId+requestId) хешируется, и все задачи с тем же ключом всегда достаются одной и той же реплике.
  * job-pollers - внутри сервиса есть очередь (в памяти, Redis, Kafka — не важно) задач «опросить страховщика N по заявке X». Каждая реплика забирает свободные задачи и обрабатывает их.
* БД master-replica, поэтому horizontal scaling aggregator = stateless.
  * horizontal scaling aggregator = stateless - логика сервиса не хранит критичных данных в памяти между запросами; всё важное лежит:
    • в БД (состояния заявок),
    • в очереди (job-pollers).
    Это позволяет просто добавлять/убирать Pod’ы («горизонтально»).

### API Web-клиента

| Операция | Путь | Протокол |
|----------|------|----------|
| Создать заявку | `POST /api/v1/osago-quotes` | **REST** |
| Подписаться на предложения | `wss://…/ws/osago/<quoteRequestId>` | **WebSocket (JSON)** |

### Cредство интеграции между веб-приложением и core-app

Выбран WebSocket & Server-Sent Events
Причины:

* Задача отобразить предложения «как только пришли».  
* Не держать браузер в цикле опроса.  
* Несколько инсуреров → несколько отдельных сообщений.
